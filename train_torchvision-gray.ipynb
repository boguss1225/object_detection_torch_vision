{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80d18665-22a6-4507-9c78-d98066a57746",
   "metadata": {},
   "source": [
    "## The command to copy data from blob to compute\n",
    "\n",
    "az storage blob directory download -c am100-data --destination-path \".\" --source-path \"proto_1\" --account-name aq1ds2storage --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0cb665-6337-427b-96cb-b0f309637532",
   "metadata": {
    "gather": {
     "logged": 1703031280423
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install opencv-python albumentations pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d45a228",
   "metadata": {
    "gather": {
     "logged": 1703031282736
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from utils.engine import train_one_epoch, evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9f1b98",
   "metadata": {},
   "source": [
    "## Configure Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dca91c9-2da0-4782-a2dd-11d81cbbe190",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1703031282899
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "DATABASE_BASE = \"../database/proto_1/\"\n",
    "train_csv_path = DATABASE_BASE + \"train.csv\"\n",
    "test_csv_path = DATABASE_BASE + \"val.csv\"\n",
    "train_image_path = DATABASE_BASE + \"train\"\n",
    "test_image_path = DATABASE_BASE + \"val\"\n",
    "model_save_path = \"trained_model/gray_proto_1/\"\n",
    "model_save_name = model_save_path + \"rcnn_b2lr001m8\"\n",
    "pretrained_model = \"trained_model/gray_proto_1/fasterrcnn_resnet50_fpn_4ep_best.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f36268",
   "metadata": {},
   "source": [
    "## Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aacd110",
   "metadata": {
    "gather": {
     "logged": 1703031283085
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(train_csv_path)\n",
    "print(train_csv.shape)\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa9b95c-2505-4166-b6c2-3cf85ac6a4fa",
   "metadata": {
    "gather": {
     "logged": 1703031283209
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename_un = train_csv[\"filename\"].unique()\n",
    "print(len(filename_un))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1fda21",
   "metadata": {
    "gather": {
     "logged": 1703031283385
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_csv = pd.read_csv(test_csv_path)\n",
    "print(test_csv.shape)\n",
    "test_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b4d6e2",
   "metadata": {
    "gather": {
     "logged": 1703031283512
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories = train_csv[\"class\"].unique()\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49e76c9",
   "metadata": {},
   "source": [
    "## Encoding classes to integers\n",
    "* 0 is for background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ada0db",
   "metadata": {
    "gather": {
     "logged": 1703031283635
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encoding functions\n",
    "class LabelMap:\n",
    "    def __init__(self, categories):\n",
    "        self.map_dict = {}\n",
    "        self.reverse_map_dict={}\n",
    "        for i, cat in enumerate(categories):\n",
    "            self.map_dict[cat] = i + 1\n",
    "            self.reverse_map_dict[i] = cat\n",
    "    def fit(self, df, column):\n",
    "        df[column] = df[column].map(self.map_dict)\n",
    "        return df\n",
    "    def inverse(self, df, column):\n",
    "        df[column] = df[column].map(self.map_dict)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27483943",
   "metadata": {
    "gather": {
     "logged": 1703031283761
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_map = LabelMap(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1714965",
   "metadata": {
    "gather": {
     "logged": 1703031283958
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_csv = label_map.fit(train_csv, \"class\")\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d3b42f",
   "metadata": {
    "gather": {
     "logged": 1703031284097
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_csv = label_map.fit(test_csv, \"class\")\n",
    "test_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3518931",
   "metadata": {},
   "source": [
    "## Torch Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d103a4",
   "metadata": {
    "gather": {
     "logged": 1703031284234
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AnimalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, image_path, categories, transforms=None,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.df = df\n",
    "        self.image_path = image_path\n",
    "        self.categories = categories\n",
    "        self.images = self.df[\"filename\"].unique()\n",
    "        self.transforms = transforms\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_file = os.path.join(self.image_path, self.images[idx])\n",
    "        img = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.astype(np.float32)\n",
    "        img = img/255.0\n",
    "        image_data = self.df[self.df['filename'] == self.images[idx]]\n",
    "        labels = torch.as_tensor(image_data[\"class\"].values, dtype=torch.int64)\n",
    "        xmins = image_data[\"xmin\"].values\n",
    "        ymins = image_data[\"ymin\"].values\n",
    "        xmaxs = image_data[\"xmax\"].values\n",
    "        ymaxs = image_data[\"ymax\"].values\n",
    "        boxes = torch.as_tensor(np.stack([xmins, ymins, xmaxs, ymaxs], axis=1), dtype=torch.float32)\n",
    "        areas = (boxes[:,3] - boxes[:,1]) * (boxes[:,2] - boxes[:,0])\n",
    "        areas = torch.as_tensor(areas, dtype=torch.float32)\n",
    "        image_id = torch.tensor([idx])\n",
    "        iscrowd = torch.zeros((len(labels),), dtype=torch.int64)\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = areas\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        if self.transforms is not None:\n",
    "            transformed = self.transforms(image=img, bboxes=boxes, labels=labels)\n",
    "            img = transformed[\"image\"]\n",
    "            target[\"boxes\"] = torch.as_tensor(transformed[\"bboxes\"],dtype=torch.float32)\n",
    "        return torch.as_tensor(img, dtype=torch.float32), target\n",
    "    def get_height_and_width(self, image):\n",
    "        image_data = self.df.loc[self.df['filename'] == image]\n",
    "        return image_data[\"width\"].values[0], image_data[\"height\"].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872f509e",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db1a390",
   "metadata": {
    "gather": {
     "logged": 1703031284366
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform_train = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.augmentations.geometric.transforms.Affine(scale=0.5, p=0.3,shear=(20), translate_percent=0.2),\n",
    "    # A.ISONoise(p=0.2),\n",
    "    # A.GaussNoise(p=0.1),\n",
    "    # A.CLAHE(p=0.1),\n",
    "    # A.CenterCrop(height=700, width=1000, p=0.3),\n",
    "    # A.HueSaturationValue(p=0.1),\n",
    "    ToTensorV2(p=1)\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6c01c",
   "metadata": {
    "gather": {
     "logged": 1703031284495
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform_test = A.Compose([\n",
    "    ToTensorV2(p=1)\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f966ba",
   "metadata": {},
   "source": [
    "## Dataloader creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a91930",
   "metadata": {
    "gather": {
     "logged": 1703031284614
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b4c1bf",
   "metadata": {
    "gather": {
     "logged": 1703031284732
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = AnimalDataset(train_csv, train_image_path, categories, transform_train)\n",
    "test_dataset = AnimalDataset(test_csv, test_image_path, categories, transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ce1281",
   "metadata": {
    "gather": {
     "logged": 1703031284852
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=2, shuffle=True, num_workers=4,\n",
    "        collate_fn=collate_fn)\n",
    "    \n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=1, shuffle=False, num_workers=4,\n",
    "    collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e5902b",
   "metadata": {},
   "source": [
    "## Plot images from dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3422560",
   "metadata": {
    "gather": {
     "logged": 1703031284970
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_images(images, targets):\n",
    "    for image, target in zip(images, targets):\n",
    "        sample = image.permute(1,2,0).cpu().numpy()\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "        boxes = target[\"boxes\"].cpu().numpy().astype(np.int32)\n",
    "        for box in boxes:\n",
    "            cv2.rectangle(sample,\n",
    "                      (box[0], box[1]),\n",
    "                      (box[2], box[3]),\n",
    "                      (220, 0, 0), 3)\n",
    "        ax.set_axis_off()\n",
    "        ax.imshow(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0154005",
   "metadata": {
    "gather": {
     "logged": 1703031289693
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "images, targets = next(iter(data_loader_train))\n",
    "print(\"Train batch\")\n",
    "plot_images(images, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b1bf7d",
   "metadata": {
    "gather": {
     "logged": 1703031295167
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "images, targets = next(iter(data_loader_test))\n",
    "print(\"test batch\")\n",
    "plot_images(images, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1cb58c",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5c18a6",
   "metadata": {},
   "source": [
    "import model from torchvision library </br>\n",
    "https://pytorch.org/vision/0.11/models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda7afe1",
   "metadata": {
    "gather": {
     "logged": 1703031295357
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_classes = len(categories)+1 # add background class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34abe42a",
   "metadata": {
    "gather": {
     "logged": 1703031295506
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision.models.detection as torch_det\n",
    "\n",
    "detection_model = torch_det.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# ... Alternatives ...\n",
    "# detection_model = torch_det.fasterrcnn_mobilenet_v3_large_320_fpn(pretrained=True)\n",
    "# detection_model = torch_det.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n",
    "# detection_model = torch_det.ssdlite320_mobilenet_v3_large(num_classes=num_classes)\n",
    "# detection_model = torch_det.ssd300_vgg16(num_classes=num_classes)\n",
    "# detection_model = torch_det.retinanet_resnet50_fpn(num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4c5616",
   "metadata": {},
   "source": [
    "adjust classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24118ceb",
   "metadata": {
    "gather": {
     "logged": 1703031295637
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for FastRCNN series... \n",
    "in_features = detection_model.roi_heads.box_predictor.cls_score.in_features\n",
    "detection_model.roi_heads.box_predictor = torch_det.faster_rcnn.FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d97f4d2",
   "metadata": {},
   "source": [
    "GPU load try and mount the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8974d3d9",
   "metadata": {
    "gather": {
     "logged": 1703031295761
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d582e",
   "metadata": {
    "gather": {
     "logged": 1703031301265
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if you have pre-trianed model\n",
    "detection_model.load_state_dict(torch.load(pretrained_model))\n",
    "\n",
    "detection_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401ad87d",
   "metadata": {},
   "source": [
    "Training and validation config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccba199-4deb-4b51-926a-075842a92edc",
   "metadata": {
    "gather": {
     "logged": 1703031305523
    }
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "# from utils.wandbutils import log_to_wandb \n",
    "hm_api_key = \"5bc9ab59d9422a7fc33e19d0de9014cda1ce4233\"\n",
    "wandb.login(key=hm_api_key)\n",
    "\n",
    "# Initialize a new W&B run\n",
    "wandb.init(\n",
    "    project=\"AM100_detection_RCNN\", \n",
    "    name='proto_1_gray',\n",
    ")\n",
    "\n",
    "# log config file to W&B\n",
    "# wandb.save(\"data/hyp.scratch.custom.yaml\")\n",
    "\n",
    "# Add other hyperparameters as needed\n",
    "wandb.config.epochs = 100\n",
    "wandb.config.batch_size = 2\n",
    "wandb.config.input_image_size = 1300\n",
    "wandb.config.learning_rate = 0.01\n",
    "wandb.config.momentum = 0.8\n",
    "wandb.config.weight_decay = 0.0005\n",
    "\n",
    "wandb.watch(detection_model, log_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e6dc1b-c005-4c3b-8eb3-2ac3bf925a49",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1703031305653
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def log_to_wandb(train_result, eval_result):\n",
    "    lr_f = float(str(train_result.meters['lr']).split()[0])\n",
    "    loss_f = float(str(train_result.meters['loss']).split()[0])\n",
    "    loss_classifier_f = float(str(train_result.meters['loss_classifier']).split()[0])\n",
    "    loss_box_reg_f = float(str(train_result.meters['loss_box_reg']).split()[0])\n",
    "    loss_objectness_f = float(str(train_result.meters['loss_objectness']).split()[0])\n",
    "    loss_rpn_box_reg_f = float(str(train_result.meters['loss_rpn_box_reg']).split()[0])\n",
    "\n",
    "    ap75 = eval_result[\"(AP)0.75\"]\n",
    "    ap50 = eval_result[\"(AP)0.50\"]\n",
    "    ap5095 = eval_result[\"(AP)0.50:0.95\"]\n",
    "    ar5095 = eval_result[\"(AR)0.50:0.95\"]\n",
    "\n",
    "    wandb.log({\"learning rate\":lr_f,\n",
    "               \"loss\":loss_f,\n",
    "               \"loss_classifier\":loss_classifier_f,\n",
    "               \"loss_box_reg\":loss_box_reg_f,\n",
    "               \"loss_objectness\":loss_objectness_f,\n",
    "               \"loss_rpn_box_reg\":loss_rpn_box_reg_f,\n",
    "               \"Avg Precision 0.75\":ap75,\n",
    "               \"Avg Precision 0.50\":ap50,\n",
    "               \"Avg Precision 0.50:0.95\":ap5095,\n",
    "               \"Avg Recall 0.50:0.95\":ar5095,})\n",
    "    \n",
    "    if lr_f == 0 :\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233dba7f-257b-46fe-a10d-33a877c74cd1",
   "metadata": {
    "gather": {
     "logged": 1703031305787
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training(model, train_loader, val_loader, epochs=10, patience=20):\n",
    "    # init valiables\n",
    "    cur_patience = patience\n",
    "    min_loss = float('inf')\n",
    "    \n",
    "    # construct an optimizer\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=0.01,\n",
    "                                momentum=0.8, weight_decay=0.0005)\n",
    "    # and a learning rate scheduler\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                   step_size=3,\n",
    "                                                   gamma=0.1)\n",
    "    for epoch in range(epochs):\n",
    "        # train for one epoch, printing every 10 iterations\n",
    "        train_result = train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq=120)\n",
    "        # update the learning rate\n",
    "        lr_scheduler.step()\n",
    "        # evaluate on the test dataset\n",
    "        eval_result = evaluate(model, val_loader, device=device)\n",
    "\n",
    "        # wandb log\n",
    "        lr_is_zero = log_to_wandb(train_result, eval_result.eval_result)\n",
    "\n",
    "        # early stopping function\n",
    "        cur_loss = float(str(train_result.meters['loss']).split()[0])\n",
    "\n",
    "        if cur_loss < min_loss : \n",
    "            min_loss = cur_loss # update min loss\n",
    "            torch.save(detection_model.state_dict(), model_save_name+'_best.pt') # save the best model\n",
    "            cur_patience = patience # reset patience\n",
    "            print(\"reset patience, saved model\")\n",
    "        else :\n",
    "            cur_patience -= 1\n",
    "            print(\"current patience:\",cur_patience, \"current loss: \",cur_loss, \"best loss: \", min_loss)\n",
    "\n",
    "        if cur_patience == 0 or lr_is_zero : # reach early stop\n",
    "            print(\"early stop at epoch {} due to no loss improve for {} epochs\".format(epoch,patience))\n",
    "            wandb.config.epochs = epoch\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b349dc",
   "metadata": {
    "gather": {
     "logged": 1703031471956
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create directory if not exist\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "# start training\n",
    "training(detection_model, data_loader_train, data_loader_test, epochs=wandb.config.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba4d6e0",
   "metadata": {},
   "source": [
    "## SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324a0f2d",
   "metadata": {
    "gather": {
     "logged": 1703031276548
    }
   },
   "outputs": [],
   "source": [
    "# Save model (parameters only)\n",
    "# torch.save(detection_model.state_dict(), model_save_name+'_last.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7b68da-094e-46c1-8870-3576f76f7862",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml-pt-tf"
  },
  "kernelspec": {
   "display_name": "Python 3.8 - Pytorch and Tensorflow",
   "language": "python",
   "name": "python38-azureml-pt-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
